{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ed0ce3",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "1. LLM powered chatbot\n",
    "2. Remebers the pervious interactions and conversations like other llms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fd1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using groq \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6875a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model laoding\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ba6904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Darshan Jain! It's nice to meet you.\\n\\nThat's great that you're an AI Engineer. It's a fascinating field with so much potential. \\n\\nWhat kind of AI work are you involved in?  Do you have any projects you're particularly excited about?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 22, 'total_tokens': 87, 'completion_time': 0.118181818, 'prompt_time': 0.002138446, 'queue_time': 0.255497103, 'total_time': 0.120320264}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--2b4cf532-1e5c-474c-ba1f-3f26ba8dd426-0', usage_metadata={'input_tokens': 22, 'output_tokens': 65, 'total_tokens': 87})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Darshan Jain and I am an AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f1bd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Darshan Jain and that you are an AI Engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or ask me? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 108, 'total_tokens': 149, 'completion_time': 0.074545455, 'prompt_time': 0.005142099, 'queue_time': 0.24720503099999996, 'total_time': 0.079687554}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--0c4fe23f-2bd3-4e78-8e09-9dedbbfad0b1-0', usage_metadata={'input_tokens': 108, 'output_tokens': 41, 'total_tokens': 149})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Darshan Jain and I am an AI Engineer\"),\n",
    "        AIMessage(content=\"Hi Darshan Jain! It's nice to meet you.\\n\\nThat's great that you're an AI Engineer. It's a fascinating field with so much potential. \\n\\nWhat kind of AI work are you involved in?  Do you have any projects you're particularly excited about?\\n\"),\n",
    "        HumanMessage(content=\"Hey , What is my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc377c",
   "metadata": {},
   "source": [
    "### Message history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef889c",
   "metadata": {},
   "source": [
    "#we can use a message history class to wrap our model and make it statefull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b4e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "#get_session_history will check wheter the session_id is present in the store (dictionary) or not . \n",
    "# if it is present in the store than all the previous chats history will be initialized for that session and it will return the session_id of the store.\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b41f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf973ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Darshan Jain and I am an AI Engineer\")],\n",
    "    config=config\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc720533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Darshan Jain, and you are an AI Engineer!  \\n\\nIs there anything else you'd like to know or talk about? üòä  I'm here to help! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 246, 'total_tokens': 288, 'completion_time': 0.076363636, 'prompt_time': 0.021364257, 'queue_time': 0.261677712, 'total_time': 0.097727893}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--46825af0-a52f-41b3-8638-df0240ee8998-0', usage_metadata={'input_tokens': 246, 'output_tokens': 42, 'total_tokens': 288})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, What is my name and what do i do?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ca7288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since I'm a large language model, I don't have access to any information about you, including your name or what you do. \\n\\nIf you'd like to tell me, I'm happy to know!  üòä  \\n\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the config----->change the session_id\n",
    "\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, What is my name and what do i do?\")],\n",
    "    config=config1,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "595da359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since i have changed the session_id ...the llm have no information about the past conversations.\n",
    "# Because of with_message_history function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97569ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Jay Modi, it's nice to meet you! \\n\\nIs there anything I can help you with today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, my name is Jay modi\")],\n",
    "    config=config1,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b32c1f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You told me your name is Jay Modi! \\n\\nIs there anything else I can help you with? üòä  \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, what is my name?\")],\n",
    "    config=config1,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa42bc",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c481036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b182f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0293de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Darshan Jain, it's nice to meet you!  \\n\\nHow can I be helpful today? üòä  \\n\\nI'm ready for your questions!  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 33, 'total_tokens': 71, 'completion_time': 0.069090909, 'prompt_time': 0.002363327, 'queue_time': 0.24940194200000002, 'total_time': 0.071454236}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--32c4fcd7-b610-434c-a33d-34e8383ba62f-0', usage_metadata={'input_tokens': 33, 'output_tokens': 38, 'total_tokens': 71})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hello,my name is Darshan Jain\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ed35356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat message histort in chain\n",
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1b0b8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Darshan K Jain! \\n\\nIt's great to meet you. How can I be of service today?  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 128, 'total_tokens': 157, 'completion_time': 0.052727273, 'prompt_time': 0.007477349, 'queue_time': 0.25376188, 'total_time': 0.060204622}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--dbe46969-c245-43da-988d-284180a9f17d-0', usage_metadata={'input_tokens': 128, 'output_tokens': 29, 'total_tokens': 157})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hii,my name is Darshan K Jain\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b013ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Darshan K Jain.  \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hello, what is my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "079a9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding more complexity.\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f46652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi, my name is Darshan K Jain and I am an AI Engineer.\")],\"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff8419ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Darshan K Jain! ‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à Bard, ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§Ü‡§∞‡•ç‡§ü‡§ø‡§´‡§ø‡§∂‡§ø‡§Ø‡§≤ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§∏ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§π‡•Ç‡§Å‡•§\\n\\n‡§Ü‡§™‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§  \\n\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6007915",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1=chain.invoke({\"messages\":[HumanMessage(content=\"Hi, my name is Darshan K Jain and I am an AI Engineer.\")],\"language\":\"Marathi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0b0fe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§ú‡•à‡§®! ‡§Æ‡§≤‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§µ‡§æ‡§ü‡§§ ‡§Ü‡§π‡•á ‡§ï‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§Æ‡§≤‡§æ ‡§≠‡•á‡§ü‡§æ‡§≤ ‡§Ü‡§π‡§æ‡§§. ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§Ü‡§π‡•á. ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§æ‡§Ø ‡§Æ‡§¶‡§§ ‡§π‡§µ‡•Ä ‡§Ü‡§π‡•á? \\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7db58",
   "metadata": {},
   "source": [
    "Lets now wrap tgis more complicated chain in a Message history class. This time , because there are multiple keys in the input , we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5591e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45c2634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Darshan Jain! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üòä  \\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi,I am Darshan Jain\")],\"language\":\"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed0a7977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Darshan Jain ‡§π‡•à‡•§ üòä  \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name ?\")],\"language\":\"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13554962",
   "metadata": {},
   "source": [
    "# Managing the conversation History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e3c8f",
   "metadata": {},
   "source": [
    "'trim_messages' is a helper to reduce how many messages we are sending to the model.\n",
    "The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and wheter to allow partial message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "173d591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c229fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PINKY\\OneDrive\\Desktop\\Chatbots_Langcahin\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\PINKY\\OneDrive\\Desktop\\Chatbots_Langcahin\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PINKY\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages= [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "\n",
    ")\n",
    "\n",
    "result=chain.invoke(\n",
    "{  \n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like?\")],\n",
    "    \"language\":\"English\"\n",
    "},\n",
    "config=config,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9941305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You like vanilla ice cream!  üç¶\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda6494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what\\'s 2 + 2\".  üòä\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=chain.invoke(\n",
    "{  \n",
    "    \"messages\":messages + [HumanMessage(content=\"What math problem did i asked?\")],\n",
    "    \"language\":\"English\"\n",
    "},\n",
    "config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "495e87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets wrap this message history\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said your name is Bob, and you like vanilla ice cream!  üç¶  \\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=chain.invoke(\n",
    "{  \n",
    "    \"messages\":messages + [HumanMessage(content=\"What is my name and what ice cream do i like?\")],\n",
    "    \"language\":\"English\"\n",
    "},\n",
    "config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "057d2b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2 + 2?\". üòä \\n\\n\\n\\nLet me know if you have any other questions!\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=chain.invoke(\n",
    "{  \n",
    "    \"messages\":messages + [HumanMessage(content=\"What math problem did i asked?\")],\n",
    "    \"language\":\"English\"\n",
    "},\n",
    "config=config,\n",
    ")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23a791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
